<p><font size="3">This means that we lost 1.76334% due to handling.</font></p>
</div>
<br/>
<div class="container">
<h4 class="header-light regular-pad">Step 2: Percentage of AFDM Remaining</h4>
<p><font size="3">The <i>AFDM()</i> function convert leaf pack dry mass to AFDM remaining (AFDMrem) as percentage. Also, this function converts the values of AFDMrem to LN (Ln.AFDMrem), which makes it easy to compare the remaining leaf mass against time in the following function (<i>slope.k()</i>).</font></p>
<!--begin.rcode
remaining <- AFDM(data= RioPriedras,
InitialWt= InitialWt,
FinalWt= FinalWt,
Frac.InitialWt= InitialFraction,
Frac.FinalWt= FinalFraction,
Treatment= Treatment,
Day= Day,
Replicate= Replicate)
remaining
remaining
remaining
end.rcode-->
</div>
<br/>
<div class="container">
<h4 class="header-light regular-pad">Step 3: Calculating the decomposition rate (<i>-k</i>)</h4>
<p><font size="3"> The <i>slope.k()</i> function relates the LN.AFDM values against time to obtain the slope that is equal to the decomposition rate  (<i>-k</i>). This procedure is run for each replica, which allows subsequent analyzes using the different <i>-k</i>. </font></p>
<!--begin.rcode
slope.k(remaining,Treatment, Replicate, Day, Ln.AFDMrem)
end.rcode-->
</div>
<br/>
<div class="container">
<h4 class="header-light regular-pad">Step 4: Calculating the r-Squared</h4>
<p><font size="3"> The <i>rsquared.k()</i> function shows the regression fit (LN.AFDM vs time) and the <i>p</i>-value for each replica. </font></p>
<!--begin.rcode
rsquared.k(remaining,Treatment, Replicate, Day, Ln.AFDMrem)
end.rcode-->
</div>
<br>
<div class="container">
<h4 class="header-light regular-pad">Step 5: Plotting the data </h4>
<p><font size="3"> Now, we show 5 plots that can be used to explore your data. However, we strongly suggest improving the plots for publications according to the requirements of journals. </font></p>
<br><p><font size="3">Plot of mean (SD) by treatment. </font></p>
<!--begin.rcode fig.show='hide'
plot.A(remaining)
end.rcode-->
<img src="{{ "/assets/img/PlotA.jpg" | relative_url }}">
</div>
<br/>
<div class="container">
<p><font size="3">Plots of replicate by treatment</font></p>
<!--begin.rcode fig.show='hide'
plot.B(remaining)
end.rcode-->
<img src="{{ "/assets/img/PlotB.jpg" | relative_url }}">
</div>
<br/>
<div class="container">
<p><font size="3">Plots of treatment trends</font></p>
<!--begin.rcode fig.show='hide'
plot.C(remaining)
end.rcode-->
<img src="{{ "/assets/img/PlotC.jpg" | relative_url }}">
</div>
<br/>
<div class="container">
<p><font size="3">Plots of replica trends</font></p>
<!--begin.rcode fig.show='hide'
plot.D(remaining)
end.rcode-->
<img src="{{ "/assets/img/PlotD.jpg" | relative_url }}">
</div>
<br/>
<div class="container">
<p><font size="3">Plot by replica</font></p>
<!--begin.rcode fig.show='hide'
plot.E(remaining)
end.rcode-->
<img src="{{ "/assets/img/PlotE.jpg" | relative_url }}">
</div>
<br/>
</div>
<br/>
pi
sin(pi/2)
cos(pi/2)
pi
sin(pi/2)
cos(pi/2)
Wingcrd <- c(59, 55, 53.5, 55, 52.5, 57.5, 53, 55)
Wingcrd
Wingcrd [3]
Wingcrd [1 : 5]
Wingcrd [-2]
sum(Wingcrd)
s.win <- sum(Wingcrd)
s.win
Tarsus <- c(22.3, 19.7, 20.8, 20.3, 20.8, 21.5, 20.6,21.5)
Head <- c(31.2, 30.4, 30.6, 30.3, 30.3, 30.8, 32.5,NA)
Wt <- c(9.5, 13.8, 14.8, 15.2, 15.5, 15.6, 15.6,15.7)
Bird<-c(Tarsus,Head,Wt)
Bird
Bird1 <- cbind(Tarsus, Head, Wt)
Bird1
Bird2 <- rbind(Tarsus, Head, Wt)
Bird2
x<-c(1:8,NA)
mean(x)
x
citation()
#### Cite specific packages?
```{r}
citation('vegan')
citation('ggplot2')
citation('randomForest')
setwd("D:\Curriculum\19_ Personal webpage\TropicalFreshwaterEcology\_pages\Lectures\data")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data")
par(mfrow=c(1,2))
plot(rda_tree_all, scaling=1, main="Odonata in Urban ponds, scaling=1")
constrained_eig <- rda_tree_all$CCA$eig/rda_tree_all$tot.chi*100
screeplot(rda_tree_all)
rda_tree_all = rda(species_2 ~ temperature + oxygen + pH +
conductivity + plants, data= env_1, scale=T)
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data")
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data")
library(ggplot2)
library(dplyr)
library(vegan)
<br/>
#### 2. Segundo paso: cargar los datos.
```{r}
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data")
library(ggplot2)
library(dplyr)
library(vegan)
<br/>
#### 2. Segundo paso: cargar los datos.
```{r}
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
setwd("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures")
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
species=read.csv("data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
species=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_species.csv", header=T, row.names=NULL, sep=",")
species=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
species=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_environmetal.csv", header=T, row.names=NULL, sep=",")
all.equal(rownames(species), rownames(env))
species_1 <- select(species, -site)
species_1 <- dplyr::select(species, -site)
env_1 <- dplyr::select(env, -site)
species_1 <- dplyr::select(species, -site)
species_1 <- dplyr::select(species, -site)
env_1 <- dplyr::select(env, -site)
species_2 <- decostand(species_1, method = "hellinger")
species_2 <- vegan::decostand(species_1, method = "hellinger")
species_2
rda_tree_all = rda(species_2 ~ temperature + oxygen + pH +
conductivity + plants, data= env_1, scale=T)
rda_tree_all = vegan::rda(species_2 ~ temperature + oxygen + pH +
conductivity + plants, data= env_1, scale=T)
rda_tree_all
summary(rda_tree_all)
head (summary (rda_tree_all))
species_1 <- dplyr::select(species, -site)
species_1 <- dplyr::select(species, -site)
env_1 <- dplyr::select(env, -site)
#### 5.  Transformar datos.
Hellinger es una transformacion recomendada por Legendre & Callagher (2001)
en datos de abundancia y con una respuesta lineal
```{r}
species_2 <- vegan::decostand(species_1, method = "hellinger")
#### 6. vegan requires that we write out each term if we are not going to
convert the factor to a dummy matrix
```{r}
rda_tree_all = vegan::rda(species_2 ~ temperature + oxygen + pH +
conductivity + plants, data= env_1, scale=T)
rda_tree_all
#### 7. Summary
http://dmcglinn.github.io/quant_methods/lessons/multivariate_models.html
Inertia is another name for variation or variance in this case.
“Total” refers to total variance
“Constrained” refers to the amount of variance explained by the explanatory variables,
“Unconstrained” refers to the residual variance.
Constrained + Unconstrained = Total.
An R2 statistic can be derived simply as Constrained / Total.
```{r}
head (summary (rda_tree_all))
#### 8. Test for colinearity
#### 8. Test for colinearity
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA
or CCA: (Bocard et al. page 175)
```{r}
vif.cca(rda_tree_all)
vegan::vif.cca(rda_tree_all)
screeplot(rda_tree_all)
screeplot(rda_tree_all)
#### 10. Percentage explained by constrained and unconstrained variables.
```{r}
constrained_eig <- rda_tree_all$CCA$eig/rda_tree_all$tot.chi*100
unconstrained_eig <- rda_tree_all$CA$eig/rda_tree_all$tot.chi*100
expl_var <- c(constrained_eig, unconstrained_eig)
barplot (expl_var[1:20], col = c(rep ('red', length (constrained_eig)), rep ('black', length (unconstrained_eig))),
las = 2, ylab = '% variation')
#### 11. Ordination plots
Scaling 1 (distance biplot): Se prioriza que la distancia entre objetos en el gráfico respete tanto como sea posible las distancias euclidias de la matriz original. Los ángulos entre vectores (variables) pueden ser distorsionados.
Scaling 2 (correlation biplot): Se prioriza que los ángulos entre vectores respeten la correlación original entre variables. La distancia entre objetos en el gráfico puede estar distorsionada.
En resumen, utilizaremos scaling 1 si nos interesa más ver cómo se diferencian los objetos, y
scaling 2 si nos interesa más ver cómo se relacionan las distintas variables.
https://bookdown.org/stephi_gascon/bookdown-demo-master_-_multivariant/_book/ordination.html
https://fukamilab.github.io/BIO202/06-B-constrained-ordination.html
```{r}
par(mfrow=c(1,2))
plot(rda_tree_all, scaling=1, main="Odonata in Urban ponds, scaling=1")
plot(rda_tree_all, scaling=2, main="Odonata in Urban ponds, scaling=2")
#### 12. Calcular las R
```{r}
(R2 <- RsquareAdj(rda_tree_all)$r.squared)
(R2adj <- RsquareAdj(rda_tree_all)$adj.r.squared)
(R2 <- vegan::RsquareAdj(rda_tree_all)$r.squared)
(R2adj <- vegan::RsquareAdj(rda_tree_all)$adj.r.squared)
set.seed(1)
anova.cca(rda_tree_all, step=1000)
vegan::anova.cca(rda_tree_all, step=1000)
vegan::anova.cca(rda_tree_all, by='axis', step=1000)
set.seed(1)
vegan::anova.cca(rda_tree_all, by='axis', step=1000)
vegan::anova.cca(rda_tree_all, by='terms', step=1000)
par(mfrow=c(1,2))
plot(rda_tree_all, scaling=1, main="Odonata in Urban ponds, scaling=1")
plot(rda_tree_all, scaling=2, main="Odonata in Urban ponds, scaling=2")
par(mfrow=c(1,2))
plot(rda_tree_all, scaling=1, main="Odonata in Urban ponds, scaling=1")
plot(rda_tree_all, scaling=2, main="Odonata in Urban ponds, scaling=2")
vegan::anova.cca(rda_tree_all, by='terms', step=1000)
#### 11. Ordination plots
Scaling 1 (distance biplot): Se prioriza que la distancia entre objetos en el gráfico respete tanto como sea posible las distancias euclidias de la matriz original. Los ángulos entre vectores (variables) pueden ser distorsionados.
Scaling 2 (correlation biplot): Se prioriza que los ángulos entre vectores respeten la correlación original entre variables. La distancia entre objetos en el gráfico puede estar distorsionada.
En resumen, utilizaremos scaling 1 si nos interesa más ver cómo se diferencian los objetos, y
scaling 2 si nos interesa más ver cómo se relacionan las distintas variables.
https://bookdown.org/stephi_gascon/bookdown-demo-master_-_multivariant/_book/ordination.html
https://fukamilab.github.io/BIO202/06-B-constrained-ordination.html
#### 10. Percentage explained by constrained and unconstrained variables.
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA
or CCA: (Bocard et al. page 175)
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA
or CCA: (Bocard et al. page 175)
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA
or CCA (Bocard et al. page 175)
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA
or CCA
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance
inflation factors (VIF), which measure the proportion by which the variance of a
regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least
examined, and avoided if possible. VIFs can be computed in vegan after RDA or CCA (Bocard et al. page 175)
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance inflation factors (VIF), which measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables.
VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible. VIFs can be computed in vegan after RDA or CCA (Bocard et al. page 175)
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance inflation factors (VIF), which measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables. VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible. VIFs can be computed in vegan after RDA or CCA (Bocard et al. page 175)
#### 8. Test for colinearity
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10).
Linear dependencies can be explored by computing the variables’ variance inflation factors (VIF), which measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables. VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible. VIFs can be computed in vegan after RDA or CCA (Bocard et al. page 175)
#### 8. Test for colinearity
Then, we can calculate Variance Inflation Factors (VIF) for each of the constraints (variables) from the environmental matrix. If we find an environmental variable with VIF>10, we'll know that this variable presents colinearity with another or other variables. In that case, we would have to delete the variable from our initial dataset and redo all the analysis. In our example, no variable is redundant with each other (all of them have VIF<10). Linear dependencies can be explored by computing the variables’ variance inflation factors (VIF), which measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables. VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible. VIFs can be computed in vegan after RDA or CCA (Bocard et al. page 175)
step_forward <- ordistep(rda_Forward_Sel, scope=formula(rda_var),
direction = "forward", perm.max=200, pstep=999)
```
?ordistep
<br/>
rda_Forward_Sel <- rda(species.hel~ 1, data= env_1)
library(ggplot2)
library(dplyr)
library(vegan)
library(ggplot2)
library(dplyr)
library(vegan)
<br/>
#### **Step 2**
Data<br>
_Cargar los datos._
```{r}
species=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_species.csv", header=T, row.names=NULL, sep=",")
env=read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/RDA_environmetal_standart.csv", header=T, row.names=NULL, sep=",")
```
<br/>
#### **Step 3**
_Remover la columna de sitos._
```{r}
species_1 <- select(species, -site)
env_1 <- select(env, -site)
```
<br/>
#### **Step 4**
**_Transformar datos._** _Hellinger es una transformaci&aacute;n recomendada por Legendre & Callagher (2001) en datos de abundancia y con una respuesta lineal._
```{r}
species.hel <- decostand(species_1, method = "hellinger")
```
<br/>
### **Seleccion de variables Forward**
_Muchas veces uno desea reducir el n&aacute;mero de variables explicatiivas de un modelo.  Para qu&eacute; hace esto? 1) Para buscar parsimonia (la soluci&oacute;n mas simple con menos variables) en el modelo; 2) Por sospechas de correlaci&oacute;n entre variables explicativas.  Esto &uacute;ltimo podr&iacute;a volver inestables los coeficientes de regresi&oacute;n de las variables explicativas del modelo (Borcard et al. 2012)._
```{r}
rda_Forward_Sel <- rda(species.hel~ 1, data= env_1)
rda_var <- rda(species.hel ~ temperature + oxygen + pH +
conductivity, data= env_1, scale=T)
# scope must give the formula of the largest possible model (maximum model)
step_forward <- ordiR2step(rda_Forward_Sel, scope=formula(rda_var),
direction = "forward", perm.max=200, pstep=999)
anova(step_forward)
laselva_full  <- read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/laSelva.csv")
stressplot(laselva.mds)
laselva_full  <- read.csv("D:/Curriculum/07_ Cursos/Course_Multivariate_Stat_for_Ecological_Data/data/Cluster_analysis_fish_PR.csv")
# Ward Hierarchical Clustering
d <- dist(species.fish, method = "euclidean") # distance matrix
species.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv")
head(species.fish)
```{r}
# Ward Hierarchical Clustering
d <- dist(species.fish, method = "euclidean") # distance matrix
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv")
head(spe.fish)
species.fish <- dplyr::select(spe.fish, Amazon_Sailfin_Catfish:Tilapia)
# Ward Hierarchical Clustering
d <- dist(species.fish, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward")
fit <- hclust(d, method="ward.D2")
plot(fit) # display dendogram
plot(fit, cex = 0.6, hang = -1) # display dendogram
spe.fish
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv")
head(spe.fish)
# Ward Hierarchical Clustering
d <- dist(spe.fish, method = "euclidean") # distance matrix
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv", row.names = 1)
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv", header = TRUE, row.names = 1)
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv", header = TRUE, row.names = F)
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv", header = TRUE, row.names = 1)
# Ward Hierarchical Clustering
d <- dist(spe.fish, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D2")
plot(fit, cex = 0.6, hang = -1) # display dendogram
cut_avg <- cutree(fit, k = 3)
# Ward Hierarchical Clustering
d <- dist(spe.fish, method = "euclidean") # distance matrix
spe.fish  <- read.csv("D:/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/Cluster_analysis_fish_PR.csv", header = TRUE, row.names = 1)
head(spe.fish)
# Ward Hierarchical Clustering
d <- dist(spe.fish, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D2")
plot(fit, cex = 0.6, hang = -1) # display dendogram
# Ward Hierarchical Clustering
d <- dist(spe.fish, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D2")
plot(fit, cex = 0.6, hang = -1) # display dendogram
```{r}
cut_avg <- cutree(fit, k = 3)
rect.hclust(fit, k = 3, border = 2:6)
# Ward Hierarchical Clustering
dist.fish <- dist(spe.fish, method = "euclidean") # distance matrix
fish_clust <- hclust(dist.fish, method="ward.D2")
plot(fish_clust, cex = 0.6, hang = -1) # display dendogram
rect.hclust(fish_clust, k = 3, border = 2:6)
abline(h = 3, col = 'red')
cut_avg
rect.hclust(fish_clust, k = 3, border = 2:6)
abline(h = 3, col = 'red')
cut_avg <- cutree(fish_clust, k = 3)
fish_clust
cut_avg <- cutree(fish_clust, k = 3)
cut_avg
cut_avg <- cutree(fish_clust, k = 100)
cut_avg <- cutree(fish_clust, k = 11)
cut_avg
table(cut_avg)
cut_avg
plot(fish_clust, cex = 0.6, hang = -1)
rect.hclust(fish_clust, k = 3, border = 2:6)
# abline(h = 100, col = 'red')
```
<br>
#### **Step 3: Cluster**
_Identificar a que grupo pertenece cada dato_
```{r}
cut_avg <- cutree(fish_clust, k = 3)
cut_avg
table(cut_avg)
View(spe.fish)
fviz_nbclust(spe.fish, FUN = hcut, method = "wss")
library(factoextra)
fviz_nbclust(spe.fish, FUN = hcut, method = "wss")
fviz_nbclust(spe.fish, FUN = hcut, method = "silhouette")
cut_avg <- cutree(fish_clust, k = 5)
cut_avg
plot(fish_clust, cex = 0.6, hang = -1)
rect.hclust(fish_clust, k = 5, border = 2:6)
fviz_nbclust(spe.fish, FUN = hcut, method = "wss")
fviz_nbclust(spe.fish, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation
labs(subtitle = "Elbow method") # add subtitle
```{r}
fviz_nbclust(spe.fish, kmeans, method = "wss") +
geom_vline(xintercept = 5, linetype = 2) + # add line for better visualisation
labs(subtitle = "Elbow method") # add subtitle
plot(fish_clust, cex = 0.6, hang = -1, ylab = "Eucludian distance")
plot(fish_clust, cex = 0.6, hang = -1,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Eucludian distance")
plot(fish_clust, cex = 0.6, hang = -1, labels = FALSE,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Eucludian distance")
NbClust(spe.fish, method = "ward.D2")
library(NbClust)
install.packages("NbClust")
library(NbClust)
NbClust(spe.fish, method = "ward.D2")
NbClust(spe.fish, k = max_nc, method = "ward.D2")
NbClust(spe.fish, k = 3, method = "ward.D2")
NbClust(spe.fish, method = "ward.D2")
?NbClust
NbClust(spe.fish, method = "ward.D2",min.nc = 2, max.nc = 11)
NbClust(spe.fish, method = "ward.D2",min.nc = 1, max.nc = 11)
NbClust(spe.fish, method = "ward.D2", max.nc = 3)
NbClust(spe.fish, diss=diss_matrix, distance = "NULL", min.nc=2, max.nc=6,
method = "ward", index = "all", alphaBeale = 0.1)
NbClust(spe.fish, diss=diss_matrix,  min.nc=2, max.nc=6,
method = "ward", index = "all", alphaBeale = 0.1)
NbClust(spe.fish, min.nc=2, max.nc=6,
method = "ward", index = "all", alphaBeale = 0.1)
NbClust(spe.fish, min.nc=2, max.nc=15, method="kmeans")
NbClust(spe.fish, min.nc=2, max.nc=15, method="ward.D2")
NbClust(spe.fish, min.nc=1, max.nc=11, method="ward.D2")
library(vegan)
library(factoextra)
spe.fish
dist.fish <- dist(spe.fish, method = "euclidean")
dist.fish
dist.fish <- dist(spe.fish, method = "euclidean")
dist.fish <- dist(spe.fish, method = "gower")
dist.fish <- dist(spe.fish, method = "bray")
?dist
dist.fish <- dist(spe.fish, method = "manhattan")
dist.fish
dist.fish <- dist(spe.fish, method = "euclidean")
dist.fish
fish_clust <- hclust(dist.fish, method = "ward.D2")
plot(fish_clust)
plot(fish_clust, cex = 0.6, hang = -1)
plot(fish_clust, cex = 0.6, hang = -1,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Euclidean distance")
dist.fish <- dist(spe.fish, method = "manhattan")
fish_clust <- hclust(dist.fish, method = "ward.D2")
plot(fish_clust, cex = 0.6, hang = -1,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Euclidean distance")
dist.fish <- dist(spe.fish, method = "minkowski")
fish_clust <- hclust(dist.fish, method = "ward.D2")
plot(fish_clust, cex = 0.6, hang = -1)
plot(fish_clust, cex = 0.6, hang = -1,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Euclidean distance")
rect.hclust(fish_clust, k=3)
rect.hclust(fish_clust, k=3,border = 2:6)
rect.hclust(fish_clust, k=3,border = 2:6)
cut_avg <- cutree(fish_clust, k = 3)
cut_avg
plot(fish_clust, cex = 0.6, hang = -1)
rect.hclust(fish_clust, k=5,border = 2:6)
fviz_nbclust(spe.fish, kmeans, method = "wss")
fviz_nbclust(spe.fish, kmeans, method = "wss") +
geom_vline(xintercept = 5, linetype = 2) + # add line for better visualisation
labs(subtitle = "Elbow method") # add subtitle
Elbow method
plot(fish_clust, cex = 0.6, hang = -1,
main = "Cluster dendrogram", sub = NULL,
xlab = "", ylab = "Euclidean distance")
rect.hclust(fish_clust, k=5,border = 2:6)
fviz_nbclust(spe.fish, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
?fviz_nbclust
spe.fish
