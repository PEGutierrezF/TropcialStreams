---
title: "Principal Component Analysis"
author: 
- "Pablo E. Guti&eacute;rrez-Fonseca"
- "`r format(Sys.time(), '%d %B, %Y')`"
layout: default
permalink: /pages/Lectures/PCA/
output: html_document
---
<br/>
<br/>

#### **Basic concepts of PCAs**
#### **Conceptos b&#225;sicos en PCAs**
PCA is an ordination used to reduce a data set with **_n_** cases (e.g., study sites) and **_p_** variables (e.g., environmental variables) to a smaller number of synthetic variables that represent most of the information in the set of original data (McCune et al. 2002).<br>

_El PCA es una ordenaci&#243;n que se utiliza para reducir un conjunto de datos con **n** casos (e.g., sitios de estudio) y **p** variables (e.g., variables ambientales) a un n&#250;mero menor de variables sint&#233;ticas que representan la mayor parte de la informaci&#243;n en el conjunto de datos original (McCune et al. 2002)._

<br/>

#### **_"prcomp"_ package**
Some blogs (e.g., [Blog 1](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-#princomp/)) recommend using the "**_prcomp_**" package to run PCAs, since it uses the singular value decomposition [(SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition), which has slightly better numerical accuracy compared to other packages like "**_princomp_**".<br>

_Algunos blogs (e.g., [Blog 1](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-#princomp/)) recomiendan usar el paquete "**prcomp**" para ejecutar PCA, ya que usa la descomposici&#243;n de valores singulares [(SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition) que tiene una precisi&#243;n num&#233;rica ligeramente mejor comparado con "**princomp**"._

<br/>

#### **Standardization and/or Normalization**
First we will define these two concepts that are fundamental in statistical analysis and modeling:<br>
**_Standardization_** (or Z-score) refers to making the empirical distribution Y&#8764;N(0,1). That is, make the variables follow a standard normal distribution (mean **_(&#956;)_** = 0 and standard deviation **_(&#963;)_** = 1). <br>
**_Standardization_** of the samples are calculated as follows: $$z = (x-\mu)/\sigma$$

<br/>
**_Normalization_** (or Scaling) refers to scaling the variable in a certain range, usually between 0 and 1.

There is more information in this [Blog 2](https://scikit-learn.org/stable/modules/preprocessing.html#normalization)<br>

Thus, we must remember that the main objective of a PCA is to find directions that maximize the variance. If the variance of one variable is greater than that of others, we make the PCA components biased in that direction.<br>

So the best we can do is make the variance of all the variables the same. We do this by **_Standardizing_** all the variables. In contrast, **_Normalization_** does not make all variables have the same variance.<br>

<br/>
_Primero vamos a definir estos dos conceptos que son fundamentales en an&#225;lisis estad&#237;stico y modelaje:_<br>

<br/>
<br/>

#### **Step 1**
Load libraries.<br>
_Cargar las librerias que necesitas._
```{r, warning=FALSE, message=FALSE}
libraries <- c('cluster','data.table','dplyr','factoextra',
               'ggfortify','ggplot2','missForest','missMDA','labdsv')

lapply(libraries, require, character.only = TRUE)
```

<br/>

#### **Step 2**
Data<br>
_Cargar los datos._
```{r}
channel <- read.csv("D:/OneDrive - University of Vermont/Curriculum/19_ Personal webpage/TropicalFreshwaterEcology/_pages/Lectures/data/PCA_channel_form.csv",header=TRUE)
head(channel)
```

<br/>

##### **Step 2.1**
_Vamos a examinar los datos_
```{r}
summary(channel)

```

<br/>

##### **Step 2.2**
_Muchas veces, los sensores se apagan o funcional mal, o no se pudo recolectar una muestra.  Esto genera vacios.  R los reconoce como NAs.  Podemos llenar estos vacios imputando datos._
```{r}
df1 <- dplyr::select(channel, Elevacion, Ancho, Velocidad, Rocas, 
                     Canto, grava, arena, Limo)

df1_a <- missForest(df1, maxiter = 4, ntree = 100,
                    variablewise = TRUE, decreasing = FALSE, verbose=F, replace=TRUE,
                    classwt = NULL, cutoff = NULL, strata = NULL,
                    sampsize = NULL, nodesize = NULL, maxnodes = NULL,
                    xtrue = NA, parallelize = "no")
```

<br/>

##### **Step 2.3**
_2.3 Seleccionamos otras variables de interes._
```{r}

df2_a <- dplyr::select(channel, Elevacion, NAtemp, NASatO2)

```

<br/>

##### **Step 2.4**
_Unimos las dos tablas_
```{r}

new_channel <- do.call("merge", c(lapply(list(df1_a$ximp, df2_a), data.frame, 
                                         row.names=NULL), by = 0, all = TRUE, sort = FALSE))[-1]
#remove 1 elevation
new_channel <- dplyr::select(new_channel, -Elevacion.y)
```

<br/>

#### **Step 3**
_Ahora, corremos el PCA usando el dataframe que contiene las variables completas (i.e., sin NAs)._
```{r}

channel.pca <- prcomp(new_channel, center = TRUE, scale =TRUE)
summary(channel.pca)


```

<br/>

##### **Step 3.1**
_Exploremos los datos con los graficos default que tiene el paquete estadistico._
```{r}
autoplot(channel.pca)

autoplot(channel.pca, data = channel, colour = 'Forma')

autoplot(channel.pca, data = channel, colour = 'Forma', loadings = TRUE)

autoplot(channel.pca, data = channel, colour = 'Forma', loadings = TRUE,
         loadings.colour = 'blue', 
         loadings.label = TRUE, loadings.label.size = 3)
```

<br/>

##### **Step 4**
_Vamos a ver la contribucion de cada una de las variables. Podemos ver cuanto explican los primero 3 PC_
```{r}
variance <- (channel.pca$sdev)^2

# Cargar los loadings
loadings <- channel.pca$rotation
round(loadings, 2)[ , 1:3]
```

_Tambien, podemos ver cuanto explican todos los PCs_
```{r}
print(channel.pca)

rownames(loadings) <- colnames(new_channel)
scores <- channel.pca$x 
```

<br/>

3.3 Ver graficamente lo que explica cada axis.

```{r}

layout(matrix(1:2, ncol=2))
screeplot(channel.pca)
screeplot(channel.pca, type="lines")


varPercent <- variance/sum(variance) * 100
barplot(varPercent, xlab='PC', ylab='Percent Variance',
names.arg=1:length(varPercent), las=1, col='gray') +
abline(h=1/ncol(new_channel)*100, col="red")

```

<br/>

4  Otras formas de visualizar los datos.
```{r}
fviz_eig(channel.pca)


fviz_pca_biplot(channel.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969",  # Individuals color
                select.var = list(contrib = 5))


```

<br/>

4.1 Con las elipses.
```{r}

fviz_pca_ind(channel.pca, label="none", habillage=channel$Forma,
     addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")

```

<br/>

4.2 
```{r}
PCA <- fviz_pca_biplot(channel.pca, label = "var", habillage=channel$Forma,
               addEllipses=TRUE, ellipse.level=0.95,
               ggtheme = theme_minimal())

# PCA + ggsave("PCA.jpg", width=11, height=8.5)

```


<br/>
5.  Convertirlo en una data.frame para trabajarlo en ggplot2
```{r}

data <- data.table(PC1=channel.pca$x[,1], PC2=channel.pca$x[,2], Forma=  channel[,1])
data <- data[order(channel$Forma),]

ggplot(data, aes(x=PC1,y=PC2)) + 
  geom_point(size = 2, aes(color=Forma))


```

<br/>

#### **References**

McCune, B., Grace, J. B., & Urban, D. L. (2002). Analysis of ecological communities (Vol. 28). Gleneden Beach, OR: MjM software design.


<br/>
<br/>